{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6zRBAtz7a/DgW1CxFGJS7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liminovna/glossary_compiler/blob/main/glossary_oop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1) принимаемые форматы:\n",
        "  - pdf (распознанный)\n",
        "  - epub\n",
        "  - txt\n",
        "  - docx\n",
        "  - fb2\n",
        "2) языки:\n",
        "  - англ\n",
        "  - русский\n",
        "# ! добавить ocr для pdf\n",
        "# djvu\n",
        "# tf-idf или ppmi!!! пока только абсолютный порог или топ\n",
        "# добавить возможность  составлять триграммы и возможность выбирать тип н-грамм\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ByYzfyAGsmaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "ALLOWED_EXTENSIONS = ('pdf', 'txt', 'epub', 'docx', 'fb2')\n",
        "\n",
        "SUPPORTED_LANGUAGES = ('ru','en')"
      ],
      "metadata": {
        "id": "pWT8Y-5xSmce"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUh8TO0_lYaw",
        "outputId": "f2b216cf-2c90-4ad6-8e89-84bdca51f859"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.10/dist-packages (1.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymupdf"
      ],
      "metadata": {
        "id": "nVfYq2tTlPWJ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def foo():\n",
        "  for page in pymupdf.open('Alice_in_Wonderland.pdf'):\n",
        "    yield page\n",
        "\n",
        "a = foo()"
      ],
      "metadata": {
        "id": "d_fTQYKElboJ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in a:\n",
        "  print(i.number)\n",
        "  # break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xWKRXtaQLZu9",
        "outputId": "76235e16-388b-4fe6-f93a-719e48b30047"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(a).get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "BUY7NcnQpbxI",
        "outputId": "e454cc4c-a319-44e6-fade-b981aeb599bf"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ALICE’S ADVENTURES\\nIN WONDERLAND\\nby Lewis Carroll\\nwith fourty-two illustrations by John Tenniel\\nThis book is in public domain.\\nNo rigths reserved. Free for copy and distribution.\\nThis PDF book is designed and published by PDFREEBOOKS.ORG\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize, sentenize\n",
        "\n",
        "\n",
        "def foo():\n",
        "  for page in pymupdf.open('Alice_in_Wonderland.pdf'):\n",
        "    yield page\n",
        "\n",
        "a = foo()\n",
        "\n",
        "\n",
        "s = next(a).get_text()\n",
        "res = []\n",
        "\n",
        "for _ in s.split('\\n'):\n",
        "  res.extend(list(sentenize(_)))\n",
        "  # print(_)\n",
        "\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2vc-f8-nqyB",
        "outputId": "15db3494-c651-4c50-f896-9913f585260d"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0, 18, 'ALICE’S ADVENTURES'),\n",
              " Substring(0, 13, 'IN WONDERLAND'),\n",
              " Substring(0, 16, 'by Lewis Carroll'),\n",
              " Substring(0, 45, 'with fourty-two illustrations by John Tenniel'),\n",
              " Substring(0, 30, 'This book is in public domain.'),\n",
              " Substring(0, 19, 'No rigths reserved.'),\n",
              " Substring(20, 51, 'Free for copy and distribution.'),\n",
              " Substring(0,\n",
              "           58,\n",
              "           'This PDF book is designed and published by PDFREEBOOKS.ORG'),\n",
              " Substring(0, 0, '')]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(sentenize(next(a).get_text()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LopCFvpKrN3v",
        "outputId": "6cd9679f-9803-4e12-a851-6c23a48ae27a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Substring(0,\n",
              "           126,\n",
              "           'ALICE’S ADVENTURES\\nIN WONDERLAND\\nby Lewis Carroll\\nwith fourty-two illustrations by John Tenniel\\nThis book is in public domain.'),\n",
              " Substring(127, 146, 'No rigths reserved.'),\n",
              " Substring(147, 178, 'Free for copy and distribution.'),\n",
              " Substring(179,\n",
              "           237,\n",
              "           'This PDF book is designed and published by PDFREEBOOKS.ORG')]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "corpus = [\n",
        "\n",
        "    'This is the first document.',\n",
        "\n",
        "    'This book is the second document.',\n",
        "\n",
        "    'And this is the third one.',\n",
        "\n",
        "    'Is this the first document?',\n",
        "\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpmOHJwIkikz",
        "outputId": "cc58046b-7574-4a78-dca7-9be6aa3262cf"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['and', 'book', 'document', 'first', 'is', 'one', 'second', 'the',\n",
              "       'third', 'this'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(X.toarray(), columns = vectorizer.get_feature_names_out())\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF0jKwtR1iWz",
        "outputId": "e7513e85-6658-4e29-a057-57cb89555383"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        and      book  document     first        is       one    second  \\\n",
            "0  0.000000  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000   \n",
            "1  0.000000  0.556901  0.355463  0.000000  0.290614  0.000000  0.556901   \n",
            "2  0.511849  0.000000  0.000000  0.000000  0.267104  0.511849  0.000000   \n",
            "3  0.000000  0.000000  0.469791  0.580286  0.384085  0.000000  0.000000   \n",
            "\n",
            "        the     third      this  \n",
            "0  0.384085  0.000000  0.384085  \n",
            "1  0.290614  0.000000  0.290614  \n",
            "2  0.267104  0.511849  0.267104  \n",
            "3  0.384085  0.000000  0.384085  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections.abc import Iterator\n",
        "from collections import Counter\n",
        "\n",
        "class InvalidExtension(Exception):\n",
        "  pass\n",
        "\n",
        "class UnsupportedLanguage(Exception):\n",
        "  pass\n",
        "\n",
        "class NotYetImplemented(Exception):\n",
        "  pass\n",
        "\n",
        "from typing import Literal\n",
        "\n",
        "class TextProcessorRU:\n",
        "  from razdel import tokenize\n",
        "\n",
        "  STOP_WORDS = []\n",
        "\n",
        "  def __init__(self, text):\n",
        "    self.text = text\n",
        "\n",
        "  @staticmethod\n",
        "  def separate_sents(text: str) -> list:\n",
        "    sentences = []\n",
        "\n",
        "    # предварительно разбиваем текст со страницы по \\n\n",
        "    for _ in text.split('\\n'):\n",
        "      sentences.extend(list(razdel.sentenize(_)))\n",
        "    self.sentences = sentences\n",
        "    return sentences\n",
        "\n",
        "  @staticmethod\n",
        "  def tokenize(sent: str) -> list:\n",
        "    return list(razdel.tokenize(sent))\n",
        "\n",
        "  @staticmethod\n",
        "  def lemmatize(words: list) -> list:\n",
        "    lemmas = []\n",
        "    for w in words:\n",
        "      pass\n",
        "    return lemmas\n",
        "\n",
        "  def count_lemmas(self, lemma_list):\n",
        "    pass\n",
        "\n",
        "class TextProcessorEN:\n",
        "  STOP_WORDS = []\n",
        "\n",
        "  def separate_sents(text):\n",
        "    pass\n",
        "\n",
        "  def tokenize(text) -> list:\n",
        "    pass\n",
        "\n",
        "  def lemmatize(word) -> str:\n",
        "    pass\n",
        "\n",
        "  def count_lemmas(lemma_list):\n",
        "    pass\n",
        "\n",
        "def TextProcessor(lang, text):\n",
        "     counters = {\n",
        "        \"ru\": TextProcessorRU,\n",
        "        \"en\": TextProcessorEN\n",
        "    }\n",
        "\n",
        "    return counters[lang](text)\n",
        "\n",
        "class GlossaryCounter():\n",
        "  \"\"\"\n",
        "  s = 'Алисе надоело сидеть на пригорке рядом с сестрой и ничего не делать. Раза два она заглянула украдкой в книгу, которую читала её сестра, но там не было ни разговоров, ни картинок.'\n",
        "  glossary = GlossaryCounter(s)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, pages: Iterator, ngram_types, lang: str):\n",
        "    self.pages = pages\n",
        "    self.ngram_types = ngram_types\n",
        "    self.lang = lang\n",
        "\n",
        "    self.vocabulary_uni = defaultdict(tuple)\n",
        "    self.vocabulary_uni.default_factory = vocabulary_uni.__len__\n",
        "    self.feature_counter_uni = Counter()\n",
        "\n",
        "    self.location_dict = defaultdict(tuple)\n",
        "\n",
        "    self.vocabulary_bi = defaultdict(tuple)\n",
        "    self.vocabulary_bi.default_factory = vocabulary_bi.__len__\n",
        "    self.feature_counter_bi = Counter()\n",
        "\n",
        "  def preprocess(text) -> str:\n",
        "    return text.lower()\n",
        "\n",
        "  def extract(self):\n",
        "    \"\"\"\n",
        "    For every page, do ...\n",
        "    \"\"\"\n",
        "    processor = TextProcessor(self.lang)\n",
        "    while True:\n",
        "      try:\n",
        "        current_page = next(self.pages)\n",
        "        current_text = self.preprocess(current_page.get_text())\n",
        "\n",
        "        for s in processor.separate_sents(current_text):\n",
        "          if s != '':\n",
        "            lemmas = [processor.lemmatize(t) for t in processor.tokenize(s)]\n",
        "\n",
        "            for left_word_idx in range(len(lemmas)):\n",
        "              right_word_idx = left_word_idx + 1\n",
        "\n",
        "              left_w = lemmas[left_word_idx]\n",
        "              if left_w not in processor.stop_words:\n",
        "\n",
        "                feature_idx_uni = self.vocabulary_uni[left_w]\n",
        "\n",
        "                self.feature_counter_uni.update(feature_idx_uni)\n",
        "\n",
        "                if feature_idx_uni not in self.location_dict:\n",
        "                    self.location_dict[feature_idx_uni] = [(current_page.number, left_word_idx)]\n",
        "                else:\n",
        "                    self.location_dict[feature_idx_uni] = self.location_dict[feature_idx_uni] + [(current_page.number, left_word_idx)]\n",
        "\n",
        "                if right_word_idx <= len(lemmas):\n",
        "                  right_w = lemmas[right_word_idx]\n",
        "                  if right_w not in processor.stop_words\n",
        "                    feature_idx_bi = self.vocabulary_bi[(left_w,right_w)]\n",
        "\n",
        "                    self.feature_counter_bi.update(feature_idx_bi)\n",
        "\n",
        "class IteratorsCollection:\n",
        "\n",
        "  def iterate_file(filename='Alice_in_Wonderland.txt'):\n",
        "    \"\"\"\n",
        "    Read txt, pdf, epub, mobi, docx, or fb2 file using pymupdf\n",
        "    \"\"\"\n",
        "    for page in pymupdf.open(filename):\n",
        "      yield page\n",
        "\n",
        "  def iterate_djvu(filename):\n",
        "    raise NotYetImplemented('This feature is yet to be implemented')\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "class GlossaryCompiler:\n",
        "\n",
        "  \"\"\"\n",
        "  Методы класса:\n",
        "  а) вытащить топ n монограм и биграм\n",
        "  б) выбрать типы n-грамм\n",
        "  в) выгрузить в csv или xlsx и указать название аутпута\n",
        "  \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def get_extension(filename: str) -> str:\n",
        "    \"\"\"\n",
        "    >>> get_extension('Alice_in_Wonderland.txt')\n",
        "    'txt'\n",
        "    >>> get_extension('Катехизис.pdf')\n",
        "    'pdf'\n",
        "    \"\"\"\n",
        "    res = filename.split('.')[-1]\n",
        "    if res in ALLOWED_EXTENSIONS:\n",
        "      return res\n",
        "    raise InvalidExtension('Could not determine the file extension or the file extension is not allowed')\n",
        "\n",
        "  @staticmethod\n",
        "  def check_language(s: str):\n",
        "    if s.lower() in SUPPORTED_LANGUAGES:\n",
        "      return s.lower()\n",
        "    raise UnsupportedLanguage(f'Language {s} is not supported')\n",
        "\n",
        "  def __init__(self, filename: str, lang: Literal[SUPPORTED_LANGUAGES], page_size: int=2000) -> None:\n",
        "    self.filename = filename\n",
        "    self.page_size = page_size\n",
        "    self.extension = self.get_extension(filename.lower())\n",
        "    self.lang = self.check_language(lang)\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "    return f'ready to process {self.extension.upper()}-file {self.filename}'\n",
        "\n",
        "  def build_vocab(self, ngram_types: list[int] = [1,2]):\n",
        "    # words_total = 0\n",
        "    # loc_dict = dict() # {'lemma': ((1,15), (1,35))}\n",
        "    # unigram_cntr = defaultdict(tuple)\n",
        "\n",
        "    if self.extension in ('pdf', 'txt', 'epub', 'docx', 'fb2'):\n",
        "      pages = IteratorsCollection.iterate_file(self.filename)\n",
        "    elif self.extension == ('djvu'):\n",
        "      pages = IteratorsCollection.iterate_djvu()\n",
        "\n",
        "    self.vocab = GlossaryCounter(pages=self.pages, ngram_types=self.ngram_types, lang=self.lang)\n",
        "    return self\n",
        "\n",
        "  def compile_glossary(self, top_n, united=False, min_threshold='auto'):\n",
        "    pass\n",
        "\n",
        "inst = GlossaryCompiler(filename='Alice_in_Wonderland.txt', lang='RU')\n",
        "inst.build_vocab()\n",
        "inst.pass(top_n=100, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhGjU1p32Jz2",
        "outputId": "87874aa3-2da9-4608-cf5c-f3463f6ff4df"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import array\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "stop_words = []\n",
        "\n",
        "vocabulary_uni = defaultdict(tuple)\n",
        "vocabulary_uni.default_factory = vocabulary_uni.__len__\n",
        "\n",
        "vocabulary_bi = defaultdict(tuple)\n",
        "vocabulary_bi.default_factory = vocabulary_bi.__len__\n",
        "\n",
        "# values = array.array(str(\"i\"))\n",
        "# j_indices = []\n",
        "# indptr = []\n",
        "\n",
        "# indptr.append(0)\n",
        "feature_counter_uni = Counter()\n",
        "feature_counter_bi = Counter()\n",
        "\n",
        "location_dict = defaultdict(tuple)\n",
        "\n",
        "a = ['a', 'b', 'c', 'a', 'b', 'b']\n",
        "found_page = 0\n",
        "for l, k in zip(a, a[1:]+['']):\n",
        "  print(found_page)\n",
        "  if l not in stop_words:\n",
        "    # print((l, k))\n",
        "  # for l in ['a', 'b', 'c', 'a', 'b', 'b']:\n",
        "    feature_idx_uni = vocabulary_uni[l]\n",
        "    feature_idx_bi = vocabulary_bi[(l,k)]\n",
        "\n",
        "    print((vocabulary_uni.items(), vocabulary_bi.items()))\n",
        "\n",
        "    if feature_idx_uni not in feature_counter_uni:\n",
        "        feature_counter_uni.update(feature_idx_uni)\n",
        "    else:\n",
        "        feature_counter_uni.update(feature_idx_uni)\n",
        "\n",
        "    if feature_idx_bi not in feature_counter_bi:\n",
        "        feature_counter_bi.update(feature_idx_bi)\n",
        "    else:\n",
        "        feature_counter_bi.update(feature_idx_bi)\n",
        "\n",
        "    if feature_idx_uni not in location_dict:\n",
        "        location_dict[feature_idx_uni] = ((0, 0))\n",
        "    else:\n",
        "        location_dict[feature_idx_uni] = location_dict[feature_idx_uni] + (found_page,)\n",
        "  found_page += 1\n",
        "\n",
        "# j_indices.extend(feature_counter.keys())\n",
        "# values.extend(feature_counter.values())\n",
        "# indptr.append(len(j_indices))\n",
        "\n",
        "\n",
        "print((feature_counter_uni, vocabulary_uni.items()))\n",
        "# print((feature_counter_bi, vocabulary_bi.items()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsvFDGGd_wPy",
        "outputId": "8c18a3c5-be5c-448a-a1ee-7e931fba7544"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(dict_items([('a', 0)]), dict_items([(('a', 'b'), 0)]))\n",
            "0\n",
            "(dict_items([('a', 0), ('b', 1)]), dict_items([(('a', 'b'), 0), (('b', 'c'), 1)]))\n",
            "0\n",
            "(dict_items([('a', 0), ('b', 1), ('c', 2)]), dict_items([(('a', 'b'), 0), (('b', 'c'), 1), (('c', 'a'), 2)]))\n",
            "0\n",
            "(dict_items([('a', 0), ('b', 1), ('c', 2)]), dict_items([(('a', 'b'), 0), (('b', 'c'), 1), (('c', 'a'), 2)]))\n",
            "0\n",
            "(dict_items([('a', 0), ('b', 1), ('c', 2)]), dict_items([(('a', 'b'), 0), (('b', 'c'), 1), (('c', 'a'), 2), (('b', 'b'), 3)]))\n",
            "0\n",
            "(dict_items([('a', 0), ('b', 1), ('c', 2)]), dict_items([(('a', 'b'), 0), (('b', 'c'), 1), (('c', 'a'), 2), (('b', 'b'), 3), (('b', ''), 4)]))\n",
            "({0: 2, 1: 3, 2: 1}, dict_items([('a', 0), ('b', 1), ('c', 2)]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "location_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJD2SbmJKX4N",
        "outputId": "9abac5da-4114-4cf2-ded7-146e7cf615e2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(tuple, {0: (0, 0, 0), 1: (0, 0, 0, 0), 2: (0, 0)})"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDDUcmbB-1bS",
        "outputId": "96743178-d7a4-492b-af5f-15ffcc8c84c5"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 2, 1: 1, 2: 1}"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "th3I_0s9At4W",
        "outputId": "af52528c-1536-49ab-a607-36e59433d344"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<method-wrapper '__len__' of collections.defaultdict object at 0x7edaacd8dee0>,\n",
              "            {'a': 0, 'b': 1, 'c': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for feature in analyze(doc):\n",
        "    try:\n",
        "        feature_idx = vocabulary[feature]\n",
        "        if feature_idx not in feature_counter:\n",
        "            feature_counter[feature_idx] = 1\n",
        "        else:\n",
        "            feature_counter[feature_idx] += 1\n",
        "    except KeyError:\n",
        "        # Ignore out-of-vocabulary items for fixed_vocab=True\n",
        "        continue\n",
        "\n",
        "    j_indices.extend(feature_counter.keys())\n",
        "    values.extend(feature_counter.values())\n",
        "    indptr.append(len(j_indices))"
      ],
      "metadata": {
        "id": "V2gYhDSg8Qg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary['a']\n",
        "vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "uYqOWnp96o6J",
        "outputId": "1f8e3433-262a-4479-acf1-044ef7e83305"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'tuple' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-534c627211de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "a = defaultdict(tuple)\n",
        "a['a']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaKQaZrH5xwl",
        "outputId": "5d6841b6-3447-4ec9-f52e-8905ae103a8a"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GlossaryExporter:\n",
        "  pass"
      ],
      "metadata": {
        "id": "lIzVY5O8uIC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FileReader(filename='Alice_in_Wonderland.txt', lang='RU')\n",
        "# itr.extract_vocab(ngram_types=[1, 2, 3], threshold='auto', ) #threshold=True auto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "up55gpBoGqBP",
        "outputId": "9a801c08-84ce-4e59-bc5d-85381f920743"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnsupportedLanguage",
          "evalue": "This language (RU) is not supported",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnsupportedLanguage\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-1114e83e3f07>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Alice_in_Wonderland.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# itr.extract_vocab(bgram_types=[1, 2, 3], threshold='auto', ) #threshold=True auto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-d781897929e8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, lang, page_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_language\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-56-d781897929e8>\u001b[0m in \u001b[0;36mcheck_language\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSUPPORTED_LANGUAGES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mUnsupportedLanguage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'This language ({s}) is not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSUPPORTED_LANGUAGES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnsupportedLanguage\u001b[0m: This language (RU) is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'abcdefg'.rindex('f')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ao3JARNDvDa",
        "outputId": "42253dd5-7d5b-4f24-8e8b-9d008383f3e8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf # https://pymupdf.readthedocs.io/en/latest/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOq4FnS9tG9e",
        "outputId": "cbca46c6-d5b6-4922-8825-fa47d4eab98e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzlNqGS1sYAR",
        "outputId": "03552a43-edc0-4e01-f5d4-a478fefa3eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Razdel\n",
        "from razdel import tokenize as razdel_tokenize\n",
        "\n",
        "' | '.join([token.text for token in list(razdel_tokenize('стены покрашены в бледно-желтый цвет'))])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "o1NtKC-vsZNQ",
        "outputId": "7f711ee8-6c74-4d05-ee9d-a2d9ae27a121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'стены | покрашены | в | бледно-желтый | цвет'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}